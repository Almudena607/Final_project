{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 02:21:39.097153: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-02 02:21:39.324459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-02 02:21:39.324510: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-02 02:21:40.374014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-02 02:21:40.374189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-02 02:21:40.374203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexploratory_analysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mipynb\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_path\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 02:34:01.517876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-02 02:34:01.525256: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-02 02:34:01.525383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-EQGCG6TT): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/almudenaramirez607/Final_project/dataset/test/20/img2.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_584.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_624.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_520.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_576.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_528.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/img1.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_632.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_608.jpg',\n",
       "       '/home/almudenaramirez607/Final_project/dataset/test/20/d20_top_560.jpg'],\n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the images\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "dataset_path =  os.path.abspath(\"../dataset\")\n",
    "globpath = f\"{dataset_path}/**/*.jpg\"\n",
    "pictures = np.hstack([np.array(glob.glob(globpath, recursive = True))])\n",
    "pictures[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3515 images belonging to 21 classes.\n",
      "Found 555 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "# preprocessing the data so it matches the model's expectations\n",
    "# not using the ImageDataGenerator for dataset ampliation because it already has rotations and image edits\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "train_data = '/home/almudenaramirez607/Final_project/dataset/train'\n",
    "test_data = '/home/almudenaramirez607/Final_project/dataset/test'\n",
    "\n",
    "train_generator = ImageDataGenerator(preprocessing_function = preprocess_input).flow_from_directory(\n",
    "    train_data, \n",
    "    target_size = (480, 480), \n",
    "    color_mode= 'grayscale', \n",
    "    batch_size = 30)\n",
    "test_generator = ImageDataGenerator(preprocessing_function = preprocess_input).flow_from_directory(\n",
    "    test_data, \n",
    "    target_size = (480, 480), \n",
    "    color_mode= 'grayscale', \n",
    "    batch_size = 20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Mobilenet_v2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 5s 1us/step\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GlobalAveragePooling' from 'tensorflow.keras.layers' (/home/almudenaramirez607/miniconda3/envs/tf/lib/python3.9/site-packages/keras/api/_v2/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# we are using default weights -> imagenet\u001b[39;00m\n\u001b[1;32m      2\u001b[0m base \u001b[39m=\u001b[39m MobileNetV2(weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m, include_top \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D, GlobalAveragePooling, Dropout, Flatten, Dense\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m Sequential([\n\u001b[1;32m      8\u001b[0m     base,\n\u001b[1;32m      9\u001b[0m     GlobalAveragePooling(), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     Dense(\u001b[39m21\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[1;32m     14\u001b[0m ])\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GlobalAveragePooling' from 'tensorflow.keras.layers' (/home/almudenaramirez607/miniconda3/envs/tf/lib/python3.9/site-packages/keras/api/_v2/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# we are using default weights -> imagenet\n",
    "base = MobileNetV2(weights='imagenet', include_top = False)\n",
    "\n",
    "model = Sequential([\n",
    "    base,\n",
    "    GlobalAveragePooling2D(), \n",
    "    Dropout(0.2), \n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(210, activation='relu'), \n",
    "    Dense(21, activation='softmax')])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboarddata = TensorBoard(log_dir='logs/mobilenet_board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/mobilenet_board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0708fa9b2c25e3dbe3301dff8cd46ef3b97ba8a20f22b38ba35810833679b5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
